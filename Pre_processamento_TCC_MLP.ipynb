{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danosaku/classificacao_artigos_webofscience_mineracao_texto/blob/main/Pre_processamento_TCC_MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-JLs2pyuCS6",
        "outputId": "4896d635-52ae-4ba7-9451-09b4f1879e22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "build-essential is already the newest version (12.9ubuntu3).\n",
            "pkg-config is already the newest version (0.29.2-1ubuntu3).\n",
            "python3-dev is already the newest version (3.10.6-1~22.04).\n",
            "python3-dev set to manually installed.\n",
            "The following additional packages will be installed:\n",
            "  libpoppler-cpp0v5\n",
            "The following NEW packages will be installed:\n",
            "  libpoppler-cpp-dev libpoppler-cpp0v5 poppler-utils\n",
            "0 upgraded, 3 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 237 kB of archives.\n",
            "After this operation, 928 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpoppler-cpp0v5 amd64 22.02.0-2ubuntu0.4 [38.8 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpoppler-cpp-dev amd64 22.02.0-2ubuntu0.4 [11.7 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.4 [186 kB]\n",
            "Fetched 237 kB in 1s (384 kB/s)\n",
            "Selecting previously unselected package libpoppler-cpp0v5:amd64.\n",
            "(Reading database ... 121918 files and directories currently installed.)\n",
            "Preparing to unpack .../libpoppler-cpp0v5_22.02.0-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking libpoppler-cpp0v5:amd64 (22.02.0-2ubuntu0.4) ...\n",
            "Selecting previously unselected package libpoppler-cpp-dev:amd64.\n",
            "Preparing to unpack .../libpoppler-cpp-dev_22.02.0-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking libpoppler-cpp-dev:amd64 (22.02.0-2ubuntu0.4) ...\n",
            "Selecting previously unselected package poppler-utils.\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.4) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.4) ...\n",
            "Setting up libpoppler-cpp0v5:amd64 (22.02.0-2ubuntu0.4) ...\n",
            "Setting up libpoppler-cpp-dev:amd64 (22.02.0-2ubuntu0.4) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "import nltk\n",
        "import glob\n",
        "from nltk.stem.porter import *\n",
        "from nltk.stem import RSLPStemmer, PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "!apt install build-essential libpoppler-cpp-dev pkg-config python3-dev poppler-utils\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LnLKB6auHBp",
        "outputId": "b9439203-7863-4a6b-dce8-078c5f39d461"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]   Unzipping stemmers/rslp.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "nltk.download('punkt') # punctuation\n",
        "nltk.download('stopwords')\n",
        "nltk.download('rslp')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--2Ce29u1_fl"
      },
      "source": [
        "Download e descompactação da planilha"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbqHHt-pNYpX",
        "outputId": "3a5bf9af-7175-4b5d-95e9-b0e7a3899fe6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1xDNirOca4fKFQEp1X3kDwif2lx7P6Snk\n",
            "To: /content/Dados_webofscience.zip\n",
            "\r  0% 0.00/1.36M [00:00<?, ?B/s]\r100% 1.36M/1.36M [00:00<00:00, 31.9MB/s]\n",
            "Archive:  Dados_webofscience.zip\n",
            "  inflating: Busca final 2_expressao simplificada.xls  \n"
          ]
        }
      ],
      "source": [
        "#link do arquivo no Google Drive\n",
        "#https://drive.google.com/file/d/1kFSj_Lb2XxHT1A_YO_YDRaAFtjEKTps3/view?usp=share_link\n",
        "\n",
        "\n",
        "!gdown 1xDNirOca4fKFQEp1X3kDwif2lx7P6Snk\n",
        "!unzip Dados_webofscience.zip\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmvyUzJx2JtS"
      },
      "source": [
        "Abrir planilha como um dataframe\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kN739SKCV5Y3",
        "outputId": "4df09271-4429-4cee-8ad2-7b70d7300996"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    Publication Type                                            Authors  \\\n",
              "0                  J  Bertol, I; Gobbi, E; Barbosa, FT; Paz-Ferreiro...   \n",
              "1                  J  Xu, S; Silveira, ML; Sollenberger, LE; Viegas,...   \n",
              "2                  J  Lanzanova, ME; Eltz, FLF; Nicoloso, RD; Cassol...   \n",
              "3                  J  Freitas, MASR; Andrade, EM; Weber, OB; Palacio...   \n",
              "4                  J  da Costa, CFG; Figueiredo, RD; Oliveira, FD; S...   \n",
              "..               ...                                                ...   \n",
              "857                J  Moldes, CA; de Lima, OF; Merini, LJ; Tsai, SM;...   \n",
              "858                J   Silva, RD; Barioni, LG; Pellegrino, GQ; Moran, D   \n",
              "859                J  Zeid, M; Yu, JK; Goldowitz, I; Denton, ME; Cos...   \n",
              "860                J  Jesus, ED; Liang, C; Quensen, JF; Susilawati, ...   \n",
              "861                J  Eastwood, RJ; Tambam, BB; Aboagye, LM; Akparov...   \n",
              "\n",
              "     Book Authors Book Editors  Book Group Authors  \\\n",
              "0             NaN          NaN                 NaN   \n",
              "1             NaN          NaN                 NaN   \n",
              "2             NaN          NaN                 NaN   \n",
              "3             NaN          NaN                 NaN   \n",
              "4             NaN          NaN                 NaN   \n",
              "..            ...          ...                 ...   \n",
              "857           NaN          NaN                 NaN   \n",
              "858           NaN          NaN                 NaN   \n",
              "859           NaN          NaN                 NaN   \n",
              "860           NaN          NaN                 NaN   \n",
              "861           NaN          NaN                 NaN   \n",
              "\n",
              "                                     Author Full Names  \\\n",
              "0    Bertol, Ildegardis; Gobbi, Ederson; Barbosa, F...   \n",
              "1    Xu, S.; Silveira, M. L.; Sollenberger, L. E.; ...   \n",
              "2    Lanzanova, Mastrangello Enivar; Foletto Eltz, ...   \n",
              "3    Freitas, M. A. S. R.; Andrade, E. M.; Weber, O...   \n",
              "4    da Costa, Cristiane F. G.; Figueiredo, Ricardo...   \n",
              "..                                                 ...   \n",
              "857  Moldes, Carlos A.; Fontao de Lima Filho, Oscar...   \n",
              "858  Silva, Rafael De Oliveira; Barioni, Luis Gusta...   \n",
              "859  Zeid, M.; Yu, J. K.; Goldowitz, I.; Denton, M....   \n",
              "860  Jesus, Ederson da C.; Liang, Chao; Quensen, Jo...   \n",
              "861  Eastwood, Ruth J.; Tambam, Beri B.; Aboagye, L...   \n",
              "\n",
              "     Book Author Full Names  Group Authors  \\\n",
              "0                       NaN            NaN   \n",
              "1                       NaN            NaN   \n",
              "2                       NaN            NaN   \n",
              "3                       NaN            NaN   \n",
              "4                       NaN            NaN   \n",
              "..                      ...            ...   \n",
              "857                     NaN            NaN   \n",
              "858                     NaN            NaN   \n",
              "859                     NaN            NaN   \n",
              "860                     NaN            NaN   \n",
              "861                     NaN            NaN   \n",
              "\n",
              "                                         Article Title  \\\n",
              "0    WATER EROSION IN NATURAL GRASSLAND UNDER DIFFE...   \n",
              "1    Conversion of native rangelands into cultivate...   \n",
              "2    RESIDUAL EFFECT OF SOIL TILLAGE ON WATER EROSI...   \n",
              "3    Bedload sediment and nutrient losses in agro-e...   \n",
              "4    Runoff in Oxisol under different agroecosystem...   \n",
              "..                                                 ...   \n",
              "857  Occurrence of powdery mildew disease in wheat ...   \n",
              "858  The role of agricultural intensification in Br...   \n",
              "859  Cross-amplification of EST-derived markers amo...   \n",
              "860  Influence of corn, switchgrass, and prairie cr...   \n",
              "861  Adapting Agriculture to Climate Change: A Syno...   \n",
              "\n",
              "                                          Source Title  ...  \\\n",
              "0                REVISTA BRASILEIRA DE CIENCIA DO SOLO  ...   \n",
              "1               JOURNAL OF SOIL AND WATER CONSERVATION  ...   \n",
              "2                REVISTA BRASILEIRA DE CIENCIA DO SOLO  ...   \n",
              "3                   NUTRIENT CYCLING IN AGROECOSYSTEMS  ...   \n",
              "4    REVISTA BRASILEIRA DE ENGENHARIA AGRICOLA E AM...  ...   \n",
              "..                                                 ...  ...   \n",
              "857                        ACTA PHYSIOLOGIAE PLANTARUM  ...   \n",
              "858                               AGRICULTURAL SYSTEMS  ...   \n",
              "859                               FIELD CROPS RESEARCH  ...   \n",
              "860                    GLOBAL CHANGE BIOLOGY BIOENERGY  ...   \n",
              "861                                       PLANTS-BASEL  ...   \n",
              "\n",
              "      UT (Unique WOS ID)               Web of Science Record CLASS  \\\n",
              "0    WOS:000295854500036  View Full Record in Web of Science     1   \n",
              "1    WOS:000427469900010  View Full Record in Web of Science     1   \n",
              "2    WOS:000331652000025  View Full Record in Web of Science     1   \n",
              "3    WOS:000325848600005  View Full Record in Web of Science     1   \n",
              "4    WOS:000328262800007  View Full Record in Web of Science     1   \n",
              "..                   ...                                 ...   ...   \n",
              "857  WOS:000382675700006  View Full Record in Web of Science     0   \n",
              "858  WOS:000425567400009  View Full Record in Web of Science     1   \n",
              "859  WOS:000279096000004  View Full Record in Web of Science     0   \n",
              "860  WOS:000370492100019  View Full Record in Web of Science     1   \n",
              "861  WOS:000833763800001  View Full Record in Web of Science     0   \n",
              "\n",
              "    Unnamed: 73 Unnamed: 74 Unnamed: 75 Unnamed: 76 Unnamed: 77 Unnamed: 78  \\\n",
              "0           NaN         NaN         NaN         NaN         NaN         NaN   \n",
              "1           NaN         NaN         NaN         NaN         NaN         NaN   \n",
              "2           NaN         NaN         NaN         NaN         NaN         NaN   \n",
              "3           NaN         NaN         NaN         NaN         NaN         NaN   \n",
              "4           NaN         NaN         NaN         NaN         NaN         NaN   \n",
              "..          ...         ...         ...         ...         ...         ...   \n",
              "857         NaN         NaN         NaN         NaN         NaN         NaN   \n",
              "858         NaN         NaN         NaN         NaN         NaN         NaN   \n",
              "859         NaN         NaN         NaN         NaN         NaN         NaN   \n",
              "860         NaN         NaN         NaN         NaN         NaN         NaN   \n",
              "861         NaN         NaN         NaN         NaN         NaN         NaN   \n",
              "\n",
              "                               Unnamed: 79  \n",
              "0    OBS: 0 = não se aplica; 1 = se aplica  \n",
              "1                                      NaN  \n",
              "2                                      NaN  \n",
              "3                                      NaN  \n",
              "4                                      NaN  \n",
              "..                                     ...  \n",
              "857                                    NaN  \n",
              "858                                    NaN  \n",
              "859                                    NaN  \n",
              "860                                    NaN  \n",
              "861                                    NaN  \n",
              "\n",
              "[862 rows x 80 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-12f0026e-0094-4ef7-8af1-c3335760248b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Publication Type</th>\n",
              "      <th>Authors</th>\n",
              "      <th>Book Authors</th>\n",
              "      <th>Book Editors</th>\n",
              "      <th>Book Group Authors</th>\n",
              "      <th>Author Full Names</th>\n",
              "      <th>Book Author Full Names</th>\n",
              "      <th>Group Authors</th>\n",
              "      <th>Article Title</th>\n",
              "      <th>Source Title</th>\n",
              "      <th>...</th>\n",
              "      <th>UT (Unique WOS ID)</th>\n",
              "      <th>Web of Science Record</th>\n",
              "      <th>CLASS</th>\n",
              "      <th>Unnamed: 73</th>\n",
              "      <th>Unnamed: 74</th>\n",
              "      <th>Unnamed: 75</th>\n",
              "      <th>Unnamed: 76</th>\n",
              "      <th>Unnamed: 77</th>\n",
              "      <th>Unnamed: 78</th>\n",
              "      <th>Unnamed: 79</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>J</td>\n",
              "      <td>Bertol, I; Gobbi, E; Barbosa, FT; Paz-Ferreiro...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Bertol, Ildegardis; Gobbi, Ederson; Barbosa, F...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>WATER EROSION IN NATURAL GRASSLAND UNDER DIFFE...</td>\n",
              "      <td>REVISTA BRASILEIRA DE CIENCIA DO SOLO</td>\n",
              "      <td>...</td>\n",
              "      <td>WOS:000295854500036</td>\n",
              "      <td>View Full Record in Web of Science</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>OBS: 0 = não se aplica; 1 = se aplica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>J</td>\n",
              "      <td>Xu, S; Silveira, ML; Sollenberger, LE; Viegas,...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Xu, S.; Silveira, M. L.; Sollenberger, L. E.; ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Conversion of native rangelands into cultivate...</td>\n",
              "      <td>JOURNAL OF SOIL AND WATER CONSERVATION</td>\n",
              "      <td>...</td>\n",
              "      <td>WOS:000427469900010</td>\n",
              "      <td>View Full Record in Web of Science</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>J</td>\n",
              "      <td>Lanzanova, ME; Eltz, FLF; Nicoloso, RD; Cassol...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Lanzanova, Mastrangello Enivar; Foletto Eltz, ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>RESIDUAL EFFECT OF SOIL TILLAGE ON WATER EROSI...</td>\n",
              "      <td>REVISTA BRASILEIRA DE CIENCIA DO SOLO</td>\n",
              "      <td>...</td>\n",
              "      <td>WOS:000331652000025</td>\n",
              "      <td>View Full Record in Web of Science</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>J</td>\n",
              "      <td>Freitas, MASR; Andrade, EM; Weber, OB; Palacio...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Freitas, M. A. S. R.; Andrade, E. M.; Weber, O...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Bedload sediment and nutrient losses in agro-e...</td>\n",
              "      <td>NUTRIENT CYCLING IN AGROECOSYSTEMS</td>\n",
              "      <td>...</td>\n",
              "      <td>WOS:000325848600005</td>\n",
              "      <td>View Full Record in Web of Science</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>J</td>\n",
              "      <td>da Costa, CFG; Figueiredo, RD; Oliveira, FD; S...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>da Costa, Cristiane F. G.; Figueiredo, Ricardo...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Runoff in Oxisol under different agroecosystem...</td>\n",
              "      <td>REVISTA BRASILEIRA DE ENGENHARIA AGRICOLA E AM...</td>\n",
              "      <td>...</td>\n",
              "      <td>WOS:000328262800007</td>\n",
              "      <td>View Full Record in Web of Science</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>857</th>\n",
              "      <td>J</td>\n",
              "      <td>Moldes, CA; de Lima, OF; Merini, LJ; Tsai, SM;...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Moldes, Carlos A.; Fontao de Lima Filho, Oscar...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Occurrence of powdery mildew disease in wheat ...</td>\n",
              "      <td>ACTA PHYSIOLOGIAE PLANTARUM</td>\n",
              "      <td>...</td>\n",
              "      <td>WOS:000382675700006</td>\n",
              "      <td>View Full Record in Web of Science</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>858</th>\n",
              "      <td>J</td>\n",
              "      <td>Silva, RD; Barioni, LG; Pellegrino, GQ; Moran, D</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Silva, Rafael De Oliveira; Barioni, Luis Gusta...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The role of agricultural intensification in Br...</td>\n",
              "      <td>AGRICULTURAL SYSTEMS</td>\n",
              "      <td>...</td>\n",
              "      <td>WOS:000425567400009</td>\n",
              "      <td>View Full Record in Web of Science</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>859</th>\n",
              "      <td>J</td>\n",
              "      <td>Zeid, M; Yu, JK; Goldowitz, I; Denton, ME; Cos...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Zeid, M.; Yu, J. K.; Goldowitz, I.; Denton, M....</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Cross-amplification of EST-derived markers amo...</td>\n",
              "      <td>FIELD CROPS RESEARCH</td>\n",
              "      <td>...</td>\n",
              "      <td>WOS:000279096000004</td>\n",
              "      <td>View Full Record in Web of Science</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>860</th>\n",
              "      <td>J</td>\n",
              "      <td>Jesus, ED; Liang, C; Quensen, JF; Susilawati, ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Jesus, Ederson da C.; Liang, Chao; Quensen, Jo...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Influence of corn, switchgrass, and prairie cr...</td>\n",
              "      <td>GLOBAL CHANGE BIOLOGY BIOENERGY</td>\n",
              "      <td>...</td>\n",
              "      <td>WOS:000370492100019</td>\n",
              "      <td>View Full Record in Web of Science</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>861</th>\n",
              "      <td>J</td>\n",
              "      <td>Eastwood, RJ; Tambam, BB; Aboagye, LM; Akparov...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Eastwood, Ruth J.; Tambam, Beri B.; Aboagye, L...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Adapting Agriculture to Climate Change: A Syno...</td>\n",
              "      <td>PLANTS-BASEL</td>\n",
              "      <td>...</td>\n",
              "      <td>WOS:000833763800001</td>\n",
              "      <td>View Full Record in Web of Science</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>862 rows × 80 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-12f0026e-0094-4ef7-8af1-c3335760248b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-12f0026e-0094-4ef7-8af1-c3335760248b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-12f0026e-0094-4ef7-8af1-c3335760248b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9367e81e-1616-4928-bce6-e59ee8d8dc29\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9367e81e-1616-4928-bce6-e59ee8d8dc29')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9367e81e-1616-4928-bce6-e59ee8d8dc29 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_aa5b1169-268b-406e-b264-8b7a645b578b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('dados')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_aa5b1169-268b-406e-b264-8b7a645b578b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('dados');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dados"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "dados = pd.read_excel ('Busca final 2_expressao simplificada.xls')\n",
        "display(dados)\n",
        "!rm Busca\\ final\\ 2_expressao\\ simplificada.xls\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScnsNw1kbxVP",
        "outputId": "f3a18c6f-3e97-4a7f-f910-827dcb18dde1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Publication Type', 'Authors', 'Book Authors', 'Book Editors',\n",
              "       'Book Group Authors', 'Author Full Names', 'Book Author Full Names',\n",
              "       'Group Authors', 'Article Title', 'Source Title', 'Book Series Title',\n",
              "       'Book Series Subtitle', 'Language', 'Document Type', 'Conference Title',\n",
              "       'Conference Date', 'Conference Location', 'Conference Sponsor',\n",
              "       'Conference Host', 'Author Keywords', 'Keywords Plus', 'Abstract',\n",
              "       'Addresses', 'Affiliations', 'Reprint Addresses', 'Email Addresses',\n",
              "       'Researcher Ids', 'ORCIDs', 'Funding Orgs', 'Funding Name Preferred',\n",
              "       'Funding Text', 'Cited References', 'Cited Reference Count',\n",
              "       'Times Cited, WoS Core', 'Times Cited, All Databases',\n",
              "       '180 Day Usage Count', 'Since 2013 Usage Count', 'Publisher',\n",
              "       'Publisher City', 'Publisher Address', 'ISSN', 'eISSN', 'ISBN',\n",
              "       'Journal Abbreviation', 'Journal ISO Abbreviation', 'Publication Date',\n",
              "       'Publication Year', 'Volume', 'Issue', 'Part Number', 'Supplement',\n",
              "       'Special Issue', 'Meeting Abstract', 'Start Page', 'End Page',\n",
              "       'Article Number', 'DOI', 'DOI Link', 'Book DOI', 'Early Access Date',\n",
              "       'Number of Pages', 'WoS Categories', 'Web of Science Index',\n",
              "       'Research Areas', 'IDS Number', 'Pubmed Id', 'Open Access Designations',\n",
              "       'Highly Cited Status', 'Hot Paper Status', 'Date of Export',\n",
              "       'UT (Unique WOS ID)', 'Web of Science Record', 'CLASS', 'Unnamed: 73',\n",
              "       'Unnamed: 74', 'Unnamed: 75', 'Unnamed: 76', 'Unnamed: 77',\n",
              "       'Unnamed: 78', 'Unnamed: 79'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "dados.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwp69Vx4u6hJ"
      },
      "outputs": [],
      "source": [
        "dados = dados.dropna(subset=['Abstract', 'CLASS'])  ## Remove linhas que não contém abstract\n",
        "text = dados[['Abstract', 'Article Title', 'Author Keywords']].apply(lambda x: ' '.join(x.astype(str)), axis=1).tolist()  ## extrai o abstract, article title e authors keywors do dataframe e junta em uma única string.\n",
        "text = [i.lower() for i in text]\n",
        "ID = dados['UT (Unique WOS ID)'].values.tolist()\n",
        "#authors = dados['Authors'].values.tolist()\n",
        "#authors = [i.lower() for i in authors]\n",
        "target = dados['CLASS'].values.tolist()\n",
        "text = [i.lower() for i in text]\n",
        "#text1 = []\n",
        "#text2 = []\n",
        "#for i in text:\n",
        "#  total = len(i)/2\n",
        "#  t1 = \"\"\n",
        "#  t2 = \"\"\n",
        "#  sentences = i.split('.')\n",
        "#  for j in sentences:\n",
        "#    if len(t1) < total:\n",
        "#      t1 = t1+ j + \".\"\n",
        "#    else:\n",
        "#      t2 = t2+ j +\".\"\n",
        "#  text1.append(t1)\n",
        "#  text2.append(t2)\n",
        "#text = text2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBIuawnMhUIu"
      },
      "source": [
        "### Gera uma lista de sentenças e de classe alvo - Não vai ser usado por enquanto ( Usando em redes heterogêneas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjhlzDqIhSZS"
      },
      "outputs": [],
      "source": [
        "sentences = []\n",
        "target_sentences = []\n",
        "for i,j in zip(text, target):\n",
        "  sub_sentences = i.split('.')\n",
        "  sentences = sentences + sub_sentences\n",
        "  for k in range(len(sub_sentences)):\n",
        "    target_sentences.append(j)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBYizZPaw7mO"
      },
      "source": [
        "### Pré-processamento de texto (remoção de stopword e stemming)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqRxpS3PueaQ"
      },
      "outputs": [],
      "source": [
        "#Cria a função remove_stopwords para tokenizar o texto e remover stopwords e outras palavras desnecessárias\n",
        "\n",
        "def remove_stopwords(text,stop_words):\n",
        "\n",
        "  ##cria lista de palavras desnecessárias (se identificar alguma no decorrer do trabalho)\n",
        "\n",
        "  unnecessary_words = [\"c\",\"annals\",\"botany\",\"company\",\"elsevier\",\"science\",\"b\",\"v\",\"ltd\",\"published\",\"all\",\n",
        "                       \"rights\",\"reserved\",\"sas\",\"gmbh\",\"authors\",\"social\",\"chemical\",\"industry\",\"saab\",\"friends\",\n",
        "                       \"keai\",\"communications\",\"co\",\"copyright\",\"john\",\"wiley\",\"sons\",\"sal\"]\n",
        "  unnecessary_words = []\n",
        "  # Adiciona palavras desnecessárias às stopwords\n",
        "\n",
        "  stop_words = stop_words + unnecessary_words\n",
        "\n",
        "  # tudo para caixa baixa\n",
        "\n",
        "  s = str(text).lower()\n",
        "\n",
        "  #tokeniza o texto\n",
        "\n",
        "  tokens = word_tokenize(s)\n",
        "\n",
        "  # remove stopwords, dígitos, caracteres especiais e pontuações\n",
        "  v = [word for word in tokens if not word in stop_words and word.isalnum() and not word.isdigit()]\n",
        "\n",
        "  return v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmVvg7olw9Wt"
      },
      "outputs": [],
      "source": [
        "#Cria a função stemming para recuperar a raiz das palavras\n",
        "\n",
        "def stemming(tokens,stemmer):\n",
        "  remove_list = ['differ', 'greater', 'studi', 'aim', 'quantifi', 'total', 'ii', 'treatment', 'mm', 'h', 'plot', 'without', 'well', 'howev', 'challeng', 'particularli', 'evalu',\n",
        "                 'respons', 'consist', 'replic', 'repres', 'spp', 'occur', 'cm', 'g', 'kg', 'also', 'show', 'effect',\n",
        "                 'taken', 'ha', 'mg', 'found', 'embrapa', 'day', 'may', 'better', 'within', 'inform', 'still', 'could', 'best', 'includ', 'wherea', 'de', 'demonstr', 'approach',\n",
        "                 'across', 'main', 'number', 'conclud', 'understand', 'known', 'earli', 'overal', 'cv', 'sp', 'due', 'possibl', 'involv', 'among', 'purpos',\n",
        "                 'x', 'input', 'amount', 'data', 'obtain', 'futur', 'unit', 'must', 'regard', 'allow', 'term', 'r', 'probabl', 'record', 'part',\n",
        "                 'increase', 'result', 'higher', 'two', 'three', 'high', 'respect', 'observ', 'experi', 'four', 'affect', 'influenc', 'one', 'per', 'contribut', 'provid', 'work',\n",
        "                 'similar', 'consid', 'five', 'suggest', 'success', 'method', 'limit', 'six', 'identifi', 'research', 'thu', 'therefor', 'altern', 'need', 'order', 'ratio', 'object word'\n",
        "                 'yr', 'although', 'current', 'remain', 'would', 'except', 'matter som', 'eight', 'discuss', 'seven', 'along', 'e', 'introduc']\n",
        "                 #,'around', 'becom', 'despit', 'experiment', 'explain', 'first', 'help', 'implement', 'introduct', 'knowledg', 'like', 'month', 'much', 'municip', 'open', 'option', 'paper',\n",
        "                 #'promis', 'report', 'requir', 'review', 'shift', 'subject', 'vari', 'variabl', 'variou', 'year', 'yr']## remoção para testes\n",
        "\n",
        "  remove_list = []\n",
        "\n",
        "  tokens_stems = [stemmer.stem(word) for word in tokens]\n",
        "\n",
        "  for l in range(len(remove_list)):\n",
        "     while(remove_list[l] in tokens_stems):\n",
        "       tokens_stems.remove(remove_list[l])\n",
        "\n",
        "  ### Remove palavras consecutivas iguais\n",
        "  m = 0\n",
        "  while(m < (len(tokens_stems)-1)):\n",
        "     if (tokens_stems[m]==tokens_stems[m+1]):\n",
        "         tokens_stems.pop(m+1)\n",
        "     m+=1\n",
        "\n",
        "  return tokens_stems"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3n5sFo61xTUy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "c142a5ef-38d8-4b4b-9d84-b1441c2ddeaa"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "unterminated string literal (detected at line 6) (<ipython-input-10-104697a6f535>, line 6)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-104697a6f535>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    ---the literal stack isn't empty for entry SilvaLC96\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 6)\n"
          ]
        }
      ],
      "source": [
        "#cria função meu_tokenizador\n",
        "\n",
        "def meu_tokenizador(doc, stop_words=nltk.corpus.stopwords.words('english'), stemmer=PorterStemmer()):\n",
        "  tokens = remove_stopwords(doc,stop_words)\n",
        "  return stemming(tokens,stemmer)\n",
        "---the literal stack isn't empty for entry SilvaLC96"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9DzC3YpPD_Db"
      },
      "outputs": [],
      "source": [
        "def get_cluster_descriptors(VSM, df_documentos, cluster_id, max_terms=3):\n",
        "  df_descritors = pd.DataFrame()\n",
        "  df_descritors['word'] = VSM.get_feature_names_out()\n",
        "  df_descritors['tfidf_sum'] = VSM.transform(df_documentos[df_documentos.cluster==cluster_id]['text']).toarray().sum(axis=0)\n",
        "  df_descritors.sort_values(by='tfidf_sum',ascending=False,inplace=True)\n",
        "\n",
        "  num_docs = len(df_documentos[df_documentos.cluster==cluster_id]['text'])\n",
        "  descriptors =  df_descritors[df_descritors.tfidf_sum > 0].head(max_terms).word.to_list()\n",
        "\n",
        "  return num_docs,descriptors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5sKmmP4ElwG"
      },
      "source": [
        "As funções remove_stopwords e stemming estão sendo chamadas pela função meu_tokenizador. A função meu_tokenizador é utilizada na função para gerar os embbedings dos textos como no código abaixo. Você pode usar o CountVectorizer ou o TfidfVectorizer. O VSM.fit(texts) faz o treinamento do modelo para gerar os embbeddings. VSM.vocabulary_ mostra os n-gramas encontrados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s48df9CsEiHq"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "\n",
        "#ngram = (1,3) ## n-gramas de tamanho 1 (unigrama) até 3 (tri-grama)\n",
        "#VSM = TfidfVectorizer(tokenizer=meu_tokenizador, ngram_range = ngram)#,max_df = 0.95,min_df=0.01)\n",
        "#VSM = CountVectorizer(tokenizer=meu_tokenizador,ngram_range=ngram, min_df=2, max_df=0.95, max_features=700)\n",
        "#VSM.fit(text)\n",
        "#VSM.vocabulary_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBtGNrA8Qe82"
      },
      "outputs": [],
      "source": [
        "#from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "\n",
        "#ngram = (1,3) ## n-gramas de tamanho 1 (unigrama) até 3 (tri-grama)\n",
        "#VSM = TfidfVectorizer(tokenizer=meu_tokenizador, ngram_range = ngram)#,max_df = 0.95,min_df=0.01)\n",
        "#VSM = CountVectorizer(tokenizer=meu_tokenizador,ngram_range=ngram, min_df=2)#, max_df=0.95)#, max_features=500)\n",
        "#VSM.fit(text)\n",
        "#VSM.vocabulary_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9GTkzgncDem"
      },
      "source": [
        "remove ngrams irrelevantes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ODfUBDScbiPz"
      },
      "outputs": [],
      "source": [
        "def remove_ngrams_from_list(ngram_list):\n",
        "  irrelevant_ngrams = []\n",
        "\n",
        "\n",
        "  ngram_list = list(ngram_list)#inseri esse comando para transformar numpy array em lista, porque estava dando erro no trecho que remove os n-grams\n",
        "\n",
        "  for k in range(len(irrelevant_ngrams)):\n",
        "   if irrelevant_ngrams[k] in ngram_list:\n",
        "      ngram_list.remove(irrelevant_ngrams[k])\n",
        "\n",
        "  return ngram_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORkADCaVaPsF"
      },
      "source": [
        "Dividir o texto em conjunto de treinamento e de teste, com a proporção de 80% e 20%, respectivamente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fzh_e9mFaO2Y"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "k = 5\n",
        "split = 0\n",
        "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=7)\n",
        "kfold = skf.split(text, target)\n",
        "split_index = []\n",
        "for train, test in kfold:\n",
        "  split_index.append([train, test])\n",
        "X_train = [text[i] for i in split_index[split][0]]\n",
        "y_train = [target[i] for i in split_index[split][0]]\n",
        "X_test =  [text[i] for i in split_index[split][1]]\n",
        "ID_test =  [ID[i] for i in split_index[split][1]]\n",
        "y_test = [target[i] for i in split_index[split][1]]\n",
        "#X_train, X_test, y_train, y_test = train_test_split(text, target, train_size = 0.8, random_state=100)   ## 80% de treinamento. alterar train_size para o valor desejável. Exemplo: train_size=0.6 para 60% de treinamento\n",
        "print(X_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oekvFBjDaO0i"
      },
      "outputs": [],
      "source": [
        "sent = []\n",
        "for i in X_train:\n",
        "  s = i.split(\".\")\n",
        "  for j in s:\n",
        "    sent.append(j)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebEFJAhDTpeP"
      },
      "source": [
        "## Vetoriza as sentenças"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2h7_5KXXVoc"
      },
      "outputs": [],
      "source": [
        "def correlation(X1, lista, limiar):\n",
        "  X1[X1>0] = 1\n",
        "  dst = {}\n",
        "  lst = {}\n",
        "  for idx in range(X1.shape[1]-1):\n",
        "   if lista[idx] not in lst.keys():\n",
        "    for idx2 in range(idx+1, X1.shape[1]):\n",
        "      if lista[idx2] not in lst.keys():\n",
        "        minimo = np.linalg.norm(X1[:,idx] - X1[:,idx2])\n",
        "        if minimo <= limiar:\n",
        "          lst[lista[idx2]] = 0\n",
        "\n",
        "  return lst\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvCZQEIrkzEz"
      },
      "source": [
        "Este trecho é para alterar o vocabulário, ou seja, remove os n-gramas que são considerados irrelevantes para o problema."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwe6OhDI7Cye"
      },
      "outputs": [],
      "source": [
        "ngram = (1,4)\n",
        "\n",
        "VSM = CountVectorizer(tokenizer=meu_tokenizador,min_df=2, max_df=0.9,ngram_range=ngram, max_features=700)\n",
        "#VSM = TfidfVectorizer(tokenizer=meu_tokenizador,min_df=2, max_df=0.9,ngram_range=ngram, max_features=700)\n",
        "#VSM = CountVectorizer(tokenizer=meu_tokenizador, vocabulary = ['arroz', 'denúnc',\n",
        "#'problem', 'feij', 'banan', 'frut', 'legum', 'verd', 'ovo'], ngram_range=(1,2))\n",
        "#VSM.fit(sent)\n",
        "X = VSM.fit_transform(X_train)\n",
        "X_aux = VSM.transform(text).toarray()\n",
        "max_norm = np.max(X_aux)\n",
        "\n",
        "\n",
        "word_list = VSM.get_feature_names_out()\n",
        "#print(word_list)\n",
        "word_list = remove_ngrams_from_list(word_list)\n",
        "#new_ngram = ['---the literal stack isn't empty for entry SilvaLC96arroz', 'denúnc', 'problem', 'feij', 'banan', 'frut', 'legum', 'verd', 'ovo', 'vulner',\n",
        "#             'menos', 'lanch', 'proib', 'cond', 'higien']\n",
        "#word_list = word_list + new_ngram\n",
        "#word_list = VSM.get_feature_names()\n",
        "#word_list = word_list + ['arroz', 'denúnc', 'problem', 'feij', 'banan', 'frut', 'legum', 'verd', 'ovo']\n",
        "#print(word_list)\n",
        "\n",
        "#lst = correlation(X.toarray(), word_list, 1)\n",
        "#new_lista = []\n",
        "#cont = 0\n",
        "#for i in word_list:\n",
        "#  if i not in lst.keys():\n",
        "#     new_lista.append(i)\n",
        "#     cont+=1\n",
        "#print(len(new_lista), len(lst.keys()))\n",
        "#VSM = CountVectorizer(tokenizer=meu_tokenizador,ngram_range=ngram, vocabulary=word_list)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#VSM = CountVectorizer(tokenizer=meu_tokenizador, vocabulary = word_list, ngram_range=ngram)\n",
        "\n",
        "X = VSM.transform(X_train)\n",
        "\n",
        "X_inv = VSM.inverse_transform(X)\n",
        "X_gram = [' / '.join(ngram) for ngram in X_inv]\n",
        "k = 0\n",
        "\n",
        "while(k < len(X_gram)):\n",
        "\n",
        "  if(len(X_gram[k])==0):\n",
        "    X_gram.pop(k)\n",
        "    X_train.pop(k)\n",
        "    ID.pop(k)\n",
        "    y_train.pop(k)\n",
        "  else:\n",
        "    k+=1\n",
        "X = VSM.transform(X_train)\n",
        "#X_inv = VSM.inverse_transform(X)\n",
        "#X_gram = [' / '---the literal stack isn't empty for entry SilvaLC96.join(ngram) for ngram in X_inv]\n",
        "word_list = VSM.get_feature_names_out()\n",
        "count_list = X.toarray().sum(axis=0)\n",
        "VSM.vocabulary_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lr_LH0ufj_IP"
      },
      "source": [
        "## Imprimi a lista com os ngrams e sua frequencia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDCU0aMYj92L"
      },
      "outputs": [],
      "source": [
        "\n",
        "df_ngram = pd.DataFrame(list(zip(word_list, count_list)), columns=('ngram', 'frequency'))\n",
        "df_ngram.sort_values(by=['frequency'], ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6YLaIdPfYoH"
      },
      "source": [
        "### Networkx e Plotly\n",
        "* Construção de Redes k-NN\n",
        "* Visualização Interativa de Grafos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGAGPdQT56tD"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "import networkx as nx\n",
        "from networkx.algorithms import community"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzD24Igm_Diu"
      },
      "source": [
        "### Sklearn\n",
        "* Medidas de Similaridade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLEMyHnG_Div"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import kneighbors_graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPFg8MOej4Xj"
      },
      "outputs": [],
      "source": [
        "def show_graph_cluster(G):\n",
        "  ### ARESTAS\n",
        "  edge_x = []\n",
        "  edge_y = []\n",
        "\n",
        "  # adicionaTodo ano acontece isso.ndo as coordenadas\n",
        "  for edge in G.edges():\n",
        "      x0, y0 = G.nodes[edge[0]]['pos']\n",
        "      x1, y1 = G.nodes[edge[1]]['pos']\n",
        "      edge_x.append(x0)\n",
        "      edge_x.append(x1)\n",
        "      edge_x.append(None)\n",
        "      edge_y.append(y0)\n",
        "      edge_y.append(y1)\n",
        "      edge_y.append(None)\n",
        "\n",
        "  # definindo cor e estilo das arestas\n",
        "  edge_trace = go.Scatter(\n",
        "      x=edge_x, y=edge_y,\n",
        "      line=dict(width=2, color='#888'),\n",
        "      hoverinfo='none',\n",
        "      mode='lines')\n",
        "\n",
        "  ### VÉRTICES\n",
        "  node_x = []\n",
        "  node_y = []\n",
        "\n",
        "  # adicionando as coordenadas\n",
        "  for node in G.nodes():\n",
        "      x, y = G.nodes[node]['pos']\n",
        "      node_x.append(x)\n",
        "      node_y.append(y)\n",
        "\n",
        "  # definindo cor e estilo dos vértices\n",
        "  node_trace = go.Scatter(\n",
        "      x=node_x, y=node_y,\n",
        "      mode='markers',\n",
        "      hoverinfo='text',\n",
        "      marker=dict(\n",
        "          size=10,\n",
        "          line_width=2))\n",
        "\n",
        "\n",
        "  # adicionando texto nos vértices\n",
        "  node_text = []\n",
        "  for node in G.nodes():\n",
        "      node_text.append(G.nodes[node]['text'])\n",
        "  node_trace.text = node_text\n",
        "\n",
        "  # adicionando cores nos vértices de acordo com o cluster\n",
        "  node_labels = []\n",
        "  for node in G.nodes():\n",
        "    node_labels.append(G.nodes[node]['cluster'])\n",
        "\n",
        "  node_trace.marker.color = node_labels\n",
        "\n",
        "  # visualizando!\n",
        "  fig = go.Figure(data=[edge_trace, node_trace],\n",
        "              layout=go.Layout(\n",
        "                  showlegend=False,\n",
        "                  hovermode='closest',\n",
        "                  margin=dict(b=20,l=5,r=5,t=40),\n",
        "                  xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
        "                  yaxis=dict(showgrid=False, zeroline=False, showticklabels=False))\n",
        "                  )\n",
        "  fig.show()\n",
        "\n",
        "\n",
        "def show_graph_regularization(G):\n",
        "  ### ARESTAS\n",
        "  edge_x = []\n",
        "  edge_y = []\n",
        "\n",
        "  # adicionando as coordenadas\n",
        "  for edge in G.edges():\n",
        "      x0, y0 = G.nodes[edge[0]]['pos']\n",
        "      x1, y1 = G.nodes[edge[1]]['pos']\n",
        "      edge_x.append(x0)\n",
        "      edge_x.append(x1)\n",
        "      edge_x.append(None)\n",
        "      edge_y.append(y0)\n",
        "      edge_y.append(y1)\n",
        "      edge_y.append(None)\n",
        "\n",
        "  # definindo cor e estilo das arestas\n",
        "  edge_trace = go.Scatter(\n",
        "      x=edge_x, y=edge_y,\n",
        "      line=dict(width=1, color='#888'),\n",
        "      hoverinfo='none',\n",
        "      mode='lines')\n",
        "\n",
        "  ### VÉRTICES\n",
        "  node_x = []\n",
        "  node_y = []\n",
        "\n",
        "  # adicionando as coordenadas\n",
        "  for node in G.nodes():\n",
        "      x, y = G.nodes[node]['pos']\n",
        "      node_x.append(x)\n",
        "      node_y.append(y)\n",
        "\n",
        "  # definindo cor e estilo dos vértices\n",
        "  node_trace = go.Scatter(\n",
        "      x=node_x, y=node_y,\n",
        "      mode='markers',\n",
        "      hoverinfo='text',\n",
        "      marker=dict(\n",
        "          showscale=True,\n",
        "          colorscale='Reds',\n",
        "          size=10,\n",
        "          line_width=2))\n",
        "\n",
        "  # adicionando texto nos vértices\n",
        "  node_text = []\n",
        "  for node in G.nodes():\n",
        "      node_text.append(str(G.nodes[node]['f'])+'<br>'+G.nodes[node]['text'])\n",
        "  node_trace.text = node_text\n",
        "\n",
        "  # adicionando cores nos vértices de acordo com o label\n",
        "  node_labels = []\n",
        "  for node in G.nodes():\n",
        "    node_labels.append(G.nodes[node]['f'][0])\n",
        "\n",
        "  node_trace.marker.color = node_labels\n",
        "\n",
        "  # visualizando!\n",
        "  fig = go.Figure(data=[edge_trace, node_trace],\n",
        "              layout=go.Layout(\n",
        "                  showlegend=False,\n",
        "                  hovermode='closest',\n",
        "                  margin=dict(b=20,l=5,r=5,t=40),\n",
        "                  xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
        "                  yaxis=dict(showgrid=False, zeroline=False, showticklabels=False))\n",
        "                  )\n",
        "  fig.show()\n",
        "\n",
        "\n",
        "def simple_regularization(G,labels,max_iter=30):\n",
        "\n",
        "  # inicializando\n",
        "  for n in G.nodes():\n",
        "    G.nodes[n]['f'] = np.array([0.0])\n",
        "    if n in labels:\n",
        "      G.nodes[n]['y'] = np.array([1.0])\n",
        "      G.nodes[n]['f'] = np.array([1.0])\n",
        "\n",
        "  for i in range(0,max_iter):\n",
        "\n",
        "    # propagando\n",
        "    diff = 0\n",
        "    for node in G.nodes():\n",
        "      if node in labels: continue\n",
        "      f_new = np.array([0.0])\n",
        "      count = 0\n",
        "      for neighbor in G.neighbors(node):\n",
        "        f_new += G.nodes[neighbor]['f']\n",
        "        count += 1\n",
        "\n",
        "      f_new /= count\n",
        "      diff += np.linalg.norm(G.nodes[node]['f']-f_new)\n",
        "      G.nodes[node]['f']=f_new\n",
        "\n",
        "      if 'y' in G.nodes[node]:\n",
        "        G.nodes[node]['f'] = G.nodes[node]['y']\n",
        "    print(\"Iteration #\"+str(i+1)+\" Q(F)=\"+str(diff))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I62wK7lOKYjJ"
      },
      "source": [
        "## Criando dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUSS28TxN4l7"
      },
      "outputs": [],
      "source": [
        "df_document = pd.DataFrame(list(zip(ID, text, X_gram, target)), columns=('UT (Unique WOS ID)', 'text', 'ngrams', 'class'))\n",
        "#df_document = pd.DataFrame(list(zip(ID, text, authors, X_gram, target)), columns=('UT (Unique WOS ID)', 'text', 'Authors', 'ngrams', 'class'))#tentando incluir authors na análise... mas deve precisar de algum pré-processamento antes\n",
        "df_document"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XRThAYP_jcL"
      },
      "source": [
        "# Rede k-NN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhEZSAJ_A-v9"
      },
      "source": [
        "### Gerando uma rede usando apenas documentos dos maiores clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFugyoWAAkX5"
      },
      "outputs": [],
      "source": [
        "A = kneighbors_graph(X, n_neighbors=5, metric=\"cosine\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTmwLAVpAob_"
      },
      "outputs": [],
      "source": [
        "G = nx.Graph(A)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8T98HL6OBKj8"
      },
      "outputs": [],
      "source": [
        "cluster_id = 0\n",
        "for clusters in community.label_propagation_communities(G):\n",
        "  for doc_id in clusters:\n",
        "    G.nodes[doc_id]['cluster'] = cluster_id\n",
        "  cluster_id +=1\n",
        "\n",
        "L_clusters = []\n",
        "for index,row in df_document.iterrows():\n",
        "  L_clusters.append(G.nodes[index]['cluster'])\n",
        "df_document['cluster'] = L_clusters\n",
        "df_document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cpRzs6N3CALm"
      },
      "outputs": [],
      "source": [
        "df_cluster_stats = df_document[['ngrams','cluster']].groupby('cluster').count().sort_values(by='ngrams',ascending=False)\n",
        "df_cluster_stats.head(50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTpF1ncFjjKz"
      },
      "source": [
        "### Selecionando documentos que pertencem aos clusters selecionados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vaokHKz4Cuhn"
      },
      "outputs": [],
      "source": [
        "selected_clusters = list(df_cluster_stats.head(50).index)\n",
        "\n",
        "G2 = G.copy()\n",
        "for node in G.nodes():\n",
        "  if G.nodes[node]['cluster'] not in selected_clusters:\n",
        "    G2.remove_node(node)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMRIMO2_DblT"
      },
      "outputs": [],
      "source": [
        "pos = nx.spring_layout(G2,seed=42) # obtém coordenadas dos vértices para visualização\n",
        "for node in G2.nodes():\n",
        "  G2.nodes[node]['pos'] = pos[node]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUn4_s1HDgcT"
      },
      "outputs": [],
      "source": [
        "for index,row in df_document.iterrows(): # adiciona um texto em cada vértice.\n",
        "  if index in G2.nodes:\n",
        "    # colocamos a classe apenas para inspecionar os resultados.\n",
        "    # na prática não teremos essa informação.\n",
        "    G2.nodes[index]['text'] = str(row['class'])+\"<br>\"+str(row['text'])[:100]+\"<br>\"+str(row['ngrams'])[:100]+'...'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WEmFkz8EBZT"
      },
      "outputs": [],
      "source": [
        "show_graph_cluster(G2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mn4IRO1E_o2p"
      },
      "source": [
        "# Classificação Semissupervisionada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PO3STdahGMZf"
      },
      "outputs": [],
      "source": [
        "labels = {}\n",
        "\n",
        "for node in G2.nodes():\n",
        "  if 'differ' in G2.nodes[node]['text'] and 'treatment' in G2.nodes[node]['text']:\n",
        "    print(node,G2.nodes[node]['text'])\n",
        "    labels[node]=1\n",
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYT33l98Ny3_"
      },
      "outputs": [],
      "source": [
        "simple_regularization(G2,labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnaC1KN3J4iA"
      },
      "outputs": [],
      "source": [
        "show_graph_regularization(G2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DF8EV9L_v-K"
      },
      "source": [
        "# Análise dos Resultados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8R-Gk54thYrk"
      },
      "source": [
        "#### Visualizando os nós com maior relação aos nós rotulados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOyFmIUche1Q"
      },
      "source": [
        "#### Filtrando por meio de um limiar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKXP0c-SeCbN"
      },
      "outputs": [],
      "source": [
        "node_ids = []\n",
        "for node in G2.nodes():\n",
        "  if G2.nodes[node]['f'] > 0.5:\n",
        "    print(G2.nodes[node]['text'])\n",
        "    node_ids.append(node)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOZZbwAaeoQN"
      },
      "outputs": [],
      "source": [
        "df_document[df_document.index.isin(node_ids)].head(50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaOGB-XZewl9"
      },
      "source": [
        "### Treina um modelo MLP e imprime o resultado de classificação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xZ5PsfU1fc_"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Dense, Dropout, Conv1D,  Activation, BatchNormalization, Add\n",
        "from keras.layers import Input, Flatten, Concatenate\n",
        "from keras.models import Model, load_model\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers.pooling import GlobalMaxPooling2D, GlobalAveragePooling1D, MaxPooling2D, AveragePooling2D\n",
        "import keras\n",
        "import gc\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, cohen_kappa_score\n",
        "import tensorflow as tf\n",
        "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "    filepath='/content/tmp.h5',\n",
        "    save_weights_only=True,\n",
        "    monitor='loss',\n",
        "    mode='min',\n",
        "    save_best_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-tTP3quqwZsF"
      },
      "outputs": [],
      "source": [
        "class mlp(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Multi-Layer Perceptron for Pipeline\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_size=100, nb_filter = [64,32], lr = 1e-3, epochs = 1, batch_size = 8):\n",
        "        self.size = input_size\n",
        "        self.nb_filter = nb_filter\n",
        "        self.lr = lr\n",
        "        self.epochs = epochs\n",
        "        self.model = None\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "\n",
        "        self.model.fit(X, y,\n",
        "                   batch_size=self.batch_size,\n",
        "                   epochs=self.epochs,\n",
        "                   verbose=1,\n",
        "                   callbacks = [model_checkpoint_callback ]\n",
        "                   )\n",
        "\n",
        "        self.model.load_weights('/content/tmp.h5')\n",
        "        #!rm '/content/tmp.h5'\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.model.predict(X, batch_size = self.batch_size, verbose=0)\n",
        "\n",
        "    def mlp(self, nclasses):\n",
        "     eps = 1.1e-5\n",
        "     input_vector = Input(shape=self.size)\n",
        "     x = Dense(self.nb_filter[0], name='conv1', use_bias=True)(input_vector)\n",
        "     x = BatchNormalization(epsilon=eps)(x)\n",
        "     x = Activation('relu', name='relu1')(x)\n",
        "     x1 = Dense(self.nb_filter[1], name='conv2', use_bias=True)(x)\n",
        "     x1 = BatchNormalization(epsilon=eps)(x1)\n",
        "     x1 = Activation('relu', name='relu2')(x1)\n",
        "\n",
        "     x2 = Concatenate(axis=1)([x, x1])\n",
        "\n",
        "     x2 = Dropout(0.5)(x2)\n",
        "     x2 = Dense(nclasses, name=\"fc1\")(x2)\n",
        "     x2 = Activation('sigmoid', name='prob1')(x2)\n",
        "\n",
        "     return Model(input_vector, x2, name='Recepi_conv')\n",
        "\n",
        "\n",
        "    def get_output(self, X):\n",
        "         intermediate_layer_model = Model(inputs=self.model.input,\n",
        "                                 outputs=self.model.get_layer(self.model.layers[7].name).output)\n",
        "         out = intermediate_layer_model.predict(X, verbose=2)\n",
        "         return out\n",
        "\n",
        "\n",
        "    def compile(self):\n",
        "       self.model = self.mlp(1)\n",
        "       self.model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"mse\"])\n",
        "\n",
        "    def save(self, output):\n",
        "       self.model.save(output)\n",
        "\n",
        "    def summary(self):\n",
        "       self.model.summary()\n",
        "\n",
        "    def clear_session(self):\n",
        "         keras.backend.clear_session()\n",
        "         self.model = None\n",
        "         gc.collect()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uY87wT5Nby8E"
      },
      "outputs": [],
      "source": [
        "from sklearn import linear_model, svm\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, cohen_kappa_score, f1_score, precision_score\n",
        "X = VSM.transform(X_train).toarray()   ## Gera embbedding do conjunto de treinamento\n",
        "#X = X/max_norm\n",
        "#X = X - np.mean(X_aux)\n",
        "X_test1 = VSM.transform(X_test).toarray()\n",
        "#X_test1 = X_test1/max_norm\n",
        "#X_test1 = X_test1 - np.mean(X_aux)\n",
        "y_train = np.array(y_train) #converte para o formato numpy\n",
        "y_test = np.array(y_test)  # converte para o formato numpy\n",
        "mlp_model = mlp(input_size = X.shape[1], nb_filter = [128, 64], lr = 1e-3, epochs = 50, batch_size = 8) ## cria uma rede neural (MLP) com 2 camadas de 128 e 64 neurônios\n",
        "mlp_model.compile()\n",
        "mlp_model.summary()\n",
        "mlp_model.fit(X, y_train)  ## treina o modelo MLP com o conjunto de treinamento\n",
        "y_pred = mlp_model.predict(X_test1) ## classifica exemplos de teste e gera o resultado com valores entre 0 e 1\n",
        "y_pred2 = y_pred.copy()\n",
        "y_pred[y_pred<0.5] = 0\n",
        "y_pred[y_pred>=0.5] = 1\n",
        "print(\"Accuracy score = \",accuracy_score(y_test, y_pred))  ## acuracia  = (TP+TN)/(TP+TN+FP+FN)\n",
        "print(\"Cohen Kappa = \",cohen_kappa_score(y_test, y_pred))\n",
        "print(f\"Precision = {precision_score(y_test, y_pred)}\")\n",
        "print(\"f1 score macro = \",f1_score(y_test, y_pred, average='macro'))\n",
        "print(\"f1 score micro = \",f1_score(y_test, y_pred, average='micro'))\n",
        "print(\"Confusion matrix\")\n",
        "print( confusion_matrix(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6qVa6V6TJ4B"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "erros = []\n",
        "for i in range(y_test.shape[0]):\n",
        "  if y_pred[i]!=y_test[i]:\n",
        "     erros.append([ID_test[i], X_test[i], y_pred2[i], y_test[i]])\n",
        "df_erros = pd.DataFrame(erros, columns = ['ID', 'text', 'predicted', 'target'])\n",
        "df_erros"
      ],
      "metadata": {
        "id": "bkUOsmPeOO-3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}